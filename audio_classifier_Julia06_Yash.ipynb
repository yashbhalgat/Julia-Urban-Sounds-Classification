{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio classification in Julia\n",
    "#### Dataset: Urban Sounds dataset \n",
    "#### Author - Yash Bhalgat\n",
    "10 classes -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 10 entries:\n",
       "  \"gun_shot\"         => 7\n",
       "  \"siren\"            => 9\n",
       "  \"air_conditioner\"  => 1\n",
       "  \"children_playing\" => 3\n",
       "  \"dog_bark\"         => 4\n",
       "  \"engine_idling\"    => 6\n",
       "  \"car_horn\"         => 2\n",
       "  \"street_music\"     => 10\n",
       "  \"drilling\"         => 5\n",
       "  \"jackhammer\"       => 8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = Dict(\"air_conditioner\" => 1, \"car_horn\" => 2, \"children_playing\" => 3, \"dog_bark\" => 4, \"drilling\" => 5,\n",
    "                \"engine_idling\" => 6, \"gun_shot\" => 7, \"jackhammer\" => 8, \"siren\" => 9, \"street_music\" => 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to install some of these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images, DSP, PyPlot, MFCC, WAV, MP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For handling files\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the audio filenames in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_files = []\n",
    "for k in keys(classes)\n",
    "    mp3_files = vcat(mp3_files, glob(\"*.mp3\", string(\"UrbanSound/data/\", k, \"/\")))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = []\n",
    "for k in keys(classes)\n",
    "    wav_files = vcat(wav_files, glob(\"*.wav\", string(\"UrbanSound/data/\", k, \"/\")))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "`MFCC.jl` has a `feacalc(s; sr=sr)` function call which seemed to run VERY slowly on my laptop. And `MusicProcessing.jl` did not compile for this Julia version (there were other issues with MFCC and other versions).\n",
    "\n",
    "I wrote the following method to calculate the Mel features, which works faster. There are some hacky parameters like the FRAME_LENGTH, FRAME_INTERVAL and nfilts, which can be adjusted if it throws any errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_features (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_features(s, sr)\n",
    "    FRAME_LENGTH = 0.025\n",
    "    FRAME_INTERVAL = 0.010\n",
    "    frames = powspec(s, sr; wintime=FRAME_LENGTH, steptime=FRAME_INTERVAL);\n",
    "    energies = log.(sum(frames', 2));\n",
    "    fbanks = audspec(frames, sr; nfilts=40, fbtype=:mel)';\n",
    "    fbanks = hcat(fbanks, energies);\n",
    "    fbank_deltas = deltas(fbanks);\n",
    "    fbank_deltadeltas = deltas(fbank_deltas);\n",
    "    features = hcat(fbanks, fbank_deltas, fbank_deltadeltas);\n",
    "#     imshow(features)\n",
    "    return features\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other alternative: Spectrogram\n",
    "Or you can just take the spectrogram of the signal. But I think **better feature extraction leads to better learning!** So, use the above one.\n",
    "\n",
    "For spectrogram-based feature extraction, do the following:\n",
    "``` \n",
    "S = spectrogram(s, convert(Int, ceil(20e-3*sr)), convert(Int, ceil(10e-3*sr)); window=hanning)\n",
    "features = log10.(power(S)+10e-6)\n",
    "```\n",
    "\n",
    "Here, again, the numbers `20e-3` and `10e-3` are hacky. In the second line, I've added `10e-6` because otherwise it leads to NaN error due to the `log` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual stuff\n",
    "Now, we start with the actual training!\n",
    "\n",
    "Firstly, different functions needed for loading `.wav` and `.mp3` files. That explains the following 4-5 cells. \n",
    "\n",
    "Secondly, I've sampled first `65489` samples from each signal. If a signal is shorter than that, I've padded it to get it to that length. This leads to a fixed sized output from the `get_features` function defined above. That is then resized to `(128, 128)`. \n",
    "\n",
    "*Note: You actually don't even need to resize it, it will work anyway!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = wavread(wav_files[1], subrange=65489)\n",
    "s = audio[1][:,1]\n",
    "sr = audio[2]\n",
    "# S = spectrogram(s, convert(Int, ceil(20e-3*sr)),\n",
    "#                         convert(Int, ceil(10e-3*sr)); window=hanning)\n",
    "# features = log10.(power(S)+10e-6)\n",
    "\n",
    "features = get_features(s, sr)\n",
    "features = imresize(features, (128,128))\n",
    "labels = [classes[split(wav_files[1], \"/\")[3]]]\n",
    "sequences = [features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do this, because initial there was no resizing to the same size `(128, 128)`. Hence, all the features would be of different sizes because of different samplerates. But if we are resizing it, then you might as well allocate an arrays of zeros and go ahead from there. Nevermind for now. Let's process all the audio files.\n",
    "\n",
    "You can see that there is lot of `try-catch` going on here. That's because I am not able to load some of the audio files using the Julia wrappers. If you do, it might improve the accuracy a little bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name = \"UrbanSound/data/air_conditioner/195969.wav\"\n",
      "file_name = \"UrbanSound/data/children_playing/193697.wav\"\n",
      "file_name = \"UrbanSound/data/children_playing/193698.wav\"\n",
      "file_name = \"UrbanSound/data/children_playing/193699.wav\"\n",
      "file_name = \"UrbanSound/data/children_playing/204408.wav\"\n",
      "file_name = \"UrbanSound/data/children_playing/36429.wav\"\n",
      "file_name = \"UrbanSound/data/dog_bark/175915.wav\"\n",
      "file_name = \"UrbanSound/data/dog_bark/175917.wav\"\n",
      "file_name = \"UrbanSound/data/dog_bark/176783.wav\"\n",
      "file_name = \"UrbanSound/data/dog_bark/180256.wav\"\n",
      "file_name = \"UrbanSound/data/dog_bark/180257.wav\"\n",
      "file_name = \"UrbanSound/data/engine_idling/176787.wav\"\n",
      "file_name = \"UrbanSound/data/drilling/161129.wav\"\n",
      "file_name = \"UrbanSound/data/drilling/180029.wav\"\n",
      "sr = 22050.0f0\n",
      "file_name = \"UrbanSound/data/jackhammer/88466.wav\"\n"
     ]
    }
   ],
   "source": [
    "for file_name in wav_files[2:end]\n",
    "    try\n",
    "        try\n",
    "            ### If signal is longer than 65489, cut it!\n",
    "            audio = wavread(file_name, subrange=65489)\n",
    "            s = audio[1][:,1]\n",
    "            sr = audio[2]\n",
    "        catch\n",
    "            ### Padding with zeros if signal is shorter!\n",
    "            audio = wavread(file_name)\n",
    "            s = zeros(65489,)\n",
    "            s[1:size(audio[1],1)] = audio[1][:,1]\n",
    "            sr = audio[2]\n",
    "        end\n",
    "        \n",
    "        ### If you want Spectrogram features, uncomment the following part \n",
    "        ### and comment the line get_features.\n",
    "#         try\n",
    "#             S = spectrogram(s, convert(Int, ceil(20e-3*sr)),\n",
    "#                         convert(Int, ceil(10e-3*sr)); window=hanning)\n",
    "#         catch\n",
    "#             @show sr\n",
    "#             continue\n",
    "#         end\n",
    "#         features = log10.(power(S)+10e-6)\n",
    "        \n",
    "        features = get_features(s, sr)\n",
    "        \n",
    "        features = imresize(features, (128,128))\n",
    "        push!(labels, classes[split(file_name, \"/\")[3]])\n",
    "        push!(sequences, features)\n",
    "    catch\n",
    "        @show file_name\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_size = [size(seq,1) for seq in sequences];\n",
    "sec_size = [size(seq,2) for seq in sequences];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, did this because initially there was no resizing to a constant size. Hence, wanted to see on an average what the size turns out to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(first_size) = 128.0\n",
      "mean(sec_size) = 128.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "128.0"
      ],
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show mean(first_size)\n",
    "@show mean(sec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file_name in mp3_files\n",
    "    try\n",
    "        try\n",
    "            audio = load(file_name)\n",
    "            s = convert(Array{Float64,1}, audio.data[:,1][1:65489])\n",
    "            sr = audio.samplerate\n",
    "        catch\n",
    "            audio = load(file_name)\n",
    "            s = zeros(65489,)\n",
    "            s[1:size(audio.data,1)] = convert(Array{Float64,1}, audio.data[:,1])\n",
    "            sr = audio.samplerate\n",
    "        end\n",
    "        \n",
    "#         try\n",
    "#             S = spectrogram(s, convert(Int, ceil(20e-3*sr)),\n",
    "#                         convert(Int, ceil(10e-3*sr)); window=hanning)\n",
    "#         catch\n",
    "#             @show sr\n",
    "#             continue\n",
    "#         end\n",
    "#         features = log10.(power(S)+10e-6)\n",
    "        \n",
    "        features = get_features(s, sr)\n",
    "        \n",
    "        features = imresize(features, (128,128))\n",
    "        push!(labels, classes[split(file_name, \"/\")[3]])\n",
    "        push!(sequences, features)\n",
    "    catch\n",
    "        @show file_name\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_size = [size(seq,1) for seq in sequences];\n",
    "sec_size = [size(seq,2) for seq in sequences];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(first_size) = 128.0\n",
      "mean(sec_size) = 128.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "128.0"
      ],
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show mean(first_size)\n",
    "@show mean(sec_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "This is very important. Different filter banks have different **unnormalized** coefficients! So, if you don't normalize, there are some features in the order of `10e-2` and some in the order of `10e+2`.\n",
    "\n",
    "The following function I wrote will do it for you.\n",
    "\n",
    "*Note: Btw, there is ZCA-whitening you can do too, if you would like. But this one works almost the same.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize_features (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize_features(features)\n",
    "    features_normalized = zeros(size(features))\n",
    "    for r in 1:size(features,1)\n",
    "        for c in 1:size(features,2)\n",
    "            avg = mean(features[r,c,:])\n",
    "            stddev = std(features[r,c,:])\n",
    "            features_normalized[r,c,:] = (features[r,c,:].-avg)/stddev\n",
    "        end\n",
    "    end\n",
    "    return features_normalized\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, I am converting the array of features into a 3D-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_array = reshape(sequences[1], 128, 128, 1)\n",
    "for j in 2:size(sequences,1)\n",
    "    seq_array = cat(3, seq_array, reshape(sequences[j], 128, 128, 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1047)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(seq_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember I mentioned `feacalc` works very slow? You can uncomment and run the next cell. There is not information in these features as shown in the image generated, hence I used my custom-built function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_features = feacalc(s; sr=sr);\n",
    "# imshow(mel_features[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_normalized = normalize_features(seq_array);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1, 1047)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_normalized = reshape(seq_normalized, (128, 128, 1, 1047))\n",
    "size(seq_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-validation/test split\n",
    "Since there is no default train-test set, I randomly split the data a set of 1000 train samples and remaining validation/test samples.\n",
    "\n",
    "Line no. `10` splits the train data into batches of size 10.\n",
    "\n",
    "Don't forget to transfer all the data to the gpu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = shuffle(1:size(seq_normalized,4))\n",
    "shuffled_data = seq_normalized[:,:,:,idx]\n",
    "shuffled_labels = labels[idx]\n",
    "trainX = shuffled_data[:,:,:,1:1000]\n",
    "trainY = shuffled_labels[1:1000]\n",
    "testX = shuffled_data[:,:,:,1001:end] |> gpu\n",
    "testY = shuffled_labels[1001:end]\n",
    "one_hot_train = onehotbatch(trainY, 1:10)\n",
    "one_hot_test = onehotbatch(testY, 1:10) |> gpu\n",
    "train_data = [(trainX[:,:,:,i], one_hot_train[:,i])\n",
    "         for i in partition(1:size(trainX,4), 10)]\n",
    "train_data = gpu.(train_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows the convolutional network I used. Feel free to modify it. After a lot of tuning, for me, this worked the best.\n",
    "\n",
    "Test accuracy on 47 samples (too less) ~ 41%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((2, 2), 1=>16, NNlib.relu), #35, Conv((4, 4), 16=>8, NNlib.relu), #36, Conv((8, 8), 8=>8, NNlib.relu), #37, #38, Dense(968, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  Conv((2,2), 1=>16, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((4,4), 16=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  Conv((8,8), 8=>8, relu),\n",
    "  x -> maxpool(x, (2,2)),\n",
    "  x -> reshape(x, :, size(x, 4)),\n",
    "  Dense(968, 10), softmax) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell - because Julia 0.6 Flux does not have the `onecold` function (Julia 1.0 version has it). Just wrote one for using here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_cold (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function one_cold(preds)\n",
    "    return [indmax(preds[:,i]) for i in 1:size(preds,2)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(one_cold(m(x)) .== one_cold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#93) (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb = throttle(() -> @show(accuracy(testX, one_hot_test)), 10)\n",
    "opt = ADAM(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 1\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 2\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 3\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n",
      "accuracy(testX, one_hot_test) = 0.425531914893617\n",
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 4\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.44680851063829785\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 5\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.425531914893617\n",
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 6\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 7\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 8\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.2765957446808511\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 9\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.2765957446808511\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 10\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 11\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 12\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.3829787234042553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 13\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.3404255319148936\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 14\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.2765957446808511\n",
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.40425531914893614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mEpoch 15\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(testX, one_hot_test) = 0.3191489361702128\n",
      "accuracy(testX, one_hot_test) = 0.2978723404255319\n",
      "accuracy(testX, one_hot_test) = 0.2765957446808511\n",
      "accuracy(testX, one_hot_test) = 0.3617021276595745\n"
     ]
    }
   ],
   "source": [
    "using Flux: @epochs\n",
    "@epochs 15 Flux.train!(loss, train_data, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(testX, one_hot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are done! :)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "553123bdc1d544c98a87a2fff8542d3a",
   "lastKernelId": "bf92021a-9be1-4475-a799-3e34b64977ca"
  },
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
